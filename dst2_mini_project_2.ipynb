{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c99911",
   "metadata": {},
   "source": [
    "***Thad Hoskins***\n",
    "\n",
    "Mini-Project 2 - K-Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6816cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87e604d",
   "metadata": {},
   "source": [
    "***Question 3: Your own mini project***\n",
    "\n",
    "Find your own dataset suitable for classification or regression with at least three input variables and 200 or more cases:<br>\n",
    "Depending on the target variable of interest, you would build a k-nearest neighbor classifier or regressor using the appropriate sklearn estimator. Find some interesting unique dataset that is not popularly used in the internet. \n",
    "Address the following and include code/output snippets from b) to f). Include the response under each sub question. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d705a6",
   "metadata": {},
   "source": [
    "State your research question:\n",
    "\n",
    "Is K Nearest Neighbor Classifier good for online data usage based upon the factors of age, gender, webpages, video hours, and income.\n",
    "\n",
    "This can be used for efforts of an ISP to target power users, limit or facilitate certain online activities (no net neutrality here), market packages to users based on power user or not, etc.\n",
    "\n",
    "Since this is a classification issue, the target variable is binary: Usage\n",
    "\n",
    "usage is 1 usage data exceeds 15 gb per week, otherwise, usage is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918ebb27",
   "metadata": {},
   "source": [
    "b) Data pre-processing (to the extent deemed necessary: remember the knn algorithm depends on distances, so you need to rescale, normalize or standardize your input values to make sure no variable influences the predictions due to it scale). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d58fe9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>webpages</th>\n",
       "      <th>videohours</th>\n",
       "      <th>income</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.061389</td>\n",
       "      <td>6021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>8.516667</td>\n",
       "      <td>10239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.762222</td>\n",
       "      <td>5376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  webpages  videohours  income  usage\n",
       "0   36       0        32    0.061389    6021      0\n",
       "1   33       0        49    8.516667   10239      1\n",
       "2   46       1        22    0.000000    1374      0\n",
       "3   53       0        16    2.762222    5376      0\n",
       "4   27       1        30    0.000000    1393      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/MGCodesandStats/datasets/master/internetlogit.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "824f67cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           0\n",
       "gender        0\n",
       "webpages      0\n",
       "videohours    0\n",
       "income        0\n",
       "usage         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = data.copy()\n",
    "\n",
    "cols = [\"age\", \"webpages\", \"videohours\", \"income\"]\n",
    "\n",
    "for col in cols:\n",
    "    data_scaled[col] = scaler.fit_transform(np.array(data[col]).reshape(-1, 1))\n",
    "\n",
    "data_scaled.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dc0c3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>webpages</th>\n",
       "      <th>videohours</th>\n",
       "      <th>income</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.414634</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023404</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.501750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.341463</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041489</td>\n",
       "      <td>0.189259</td>\n",
       "      <td>0.853250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.658537</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.829268</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.061383</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.195122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>0.097561</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>0.020204</td>\n",
       "      <td>0.311583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>0.780488</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024468</td>\n",
       "      <td>0.045802</td>\n",
       "      <td>0.655500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>0.073171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>0.061265</td>\n",
       "      <td>0.106500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>0.926829</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.033951</td>\n",
       "      <td>0.926167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>0.634146</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.222488</td>\n",
       "      <td>0.975917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>966 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  gender  webpages  videohours    income  usage\n",
       "0    0.414634       0  0.023404    0.001364  0.501750      0\n",
       "1    0.341463       0  0.041489    0.189259  0.853250      1\n",
       "2    0.658537       1  0.012766    0.000000  0.114500      0\n",
       "3    0.829268       0  0.006383    0.061383  0.448000      0\n",
       "4    0.195122       1  0.021277    0.000000  0.116083      0\n",
       "..        ...     ...       ...         ...       ...    ...\n",
       "961  0.097561       0  0.017021    0.020204  0.311583      0\n",
       "962  0.780488       0  0.024468    0.045802  0.655500      0\n",
       "963  0.073171       0  0.014894    0.061265  0.106500      0\n",
       "964  0.926829       1  0.018085    0.033951  0.926167      1\n",
       "965  0.634146       1  0.010638    0.222488  0.975917      1\n",
       "\n",
       "[966 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scaled.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae9e2009",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = data_scaled.drop([\"usage\"], axis=1)\n",
    "y = data_scaled[\"usage\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d48d8",
   "metadata": {},
   "source": [
    "c) Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d90ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4646260",
   "metadata": {},
   "source": [
    "d) Model construction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d649ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9572538860103627\n",
      "Test score: 0.9123711340206185\n"
     ]
    }
   ],
   "source": [
    "knn_reg = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_reg.fit(X_train, y_train.values.flatten())\n",
    "\n",
    "print(f\"Train score: {knn_reg.score(X_train, y_train)}\")\n",
    "print(f\"Test score: {knn_reg.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416b378",
   "metadata": {},
   "source": [
    "Pretty good results. Next is a little hyper-parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb99fec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_reg.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d489d26f",
   "metadata": {},
   "source": [
    "e) Hyperparameter turning (choose whatever approach your like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2ef29d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "575ab6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
       "                         'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21,\n",
       "                                         23, 25, 27, 29, 31, 33, 35, 37, 39, 41,\n",
       "                                         43, 45, 47, 49],\n",
       "                         'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"metric\":[\"euclidean\", \"manhattan\", \"minkowski\"], \n",
    "          \"n_neighbors\": list(range(1,51, 2)), \n",
    "          \"weights\": [\"uniform\", \"distance\"]}\n",
    "gs = GridSearchCV(knn_reg, params, cv=5)\n",
    "gs.fit(X_train, y_train.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "200a0a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4afac732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(metric='euclidean', n_neighbors=7, weights='distance')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_best_estimator = gs.best_estimator_\n",
    "gs_best_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546ad06",
   "metadata": {},
   "source": [
    "f) Use the best or optimal parameter values to build a model, then compute the accuracy score for your estimator. \n",
    "Discuss about overfitting for the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "834b7123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9175257731958762\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs_best_estimator.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6b909f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = gs_best_estimator.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Train accuracy: {train_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940fd71",
   "metadata": {},
   "source": [
    "While the training accuracy is 100%, which should cause some skepticism, the accuracy of the training set is very similar to the test accuracy. The model does not appear to be overfit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
